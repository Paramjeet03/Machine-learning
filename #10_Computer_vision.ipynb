{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Computer Vision :-\n",
    "\n",
    "> Open cv is a libary in py. which use for working on image.\n",
    "\n",
    "> opencv use (B,G,R) Format.\n",
    "\n",
    "# Image :-\n",
    "\n",
    "> It is a collection of pixels.\n",
    "\n",
    "> pixel is really a matrix which have 3 value (B,G,R). The  value range from (0-255)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install opencv-python\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img=cv2.imread(r\"C:\\Users\\Paramjeet\\Desktop\\MACHINE LEARNING\\Image\\demo.jpg\")\n",
    "cv2.imshow(\"Suraj\",img)\n",
    "cv2.waitKey(10000 ) # in ms 1000ms == 1sec\n",
    "cv2.destroyWindow(\"Suraj\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img=cv2.imread(r\"C:\\Users\\Paramjeet\\Desktop\\MACHINE LEARNING\\Image\\demo.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mixing the image pixel\n",
    "f_m=img.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.random.shuffle(f_m)\n",
    "f_m=f_m.reshape(735,742,3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow(\"Suraj\",f_m)\n",
    "cv2.waitKey(10000 ) # in ms 1000ms == 1sec\n",
    "cv2.destroyWindow(\"Suraj\") # so we can arrange pixel in sequance so we can create any type image."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Broadcasting in image :-\n",
    "\n",
    ">  Image is a base is array and array is support broadcasting\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "b=np.arange(1,5)\n",
    "b*10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image=cv2.imread(r\"C:\\Users\\Paramjeet\\Desktop\\MACHINE LEARNING\\Image\\demo.jpg\") \n",
    "a=image-5\n",
    "cv2.imshow(\"Original\",image)\n",
    "cv2.imshow(\"New\",a)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# color image to black and white \n",
    "# option 1 :- \n",
    "image=cv2.imread(r\"C:\\Users\\Paramjeet\\Desktop\\MACHINE LEARNING\\Image\\demo.jpg\",0)\n",
    "cv2.imshow(\"hello\",image)\n",
    "cv2.waitKey()\n",
    "cv2.destroyWindow(\"hello\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# option 2:-\n",
    "image=cv2.imread(r\"C:\\Users\\Paramjeet\\Desktop\\MACHINE LEARNING\\Image\\demo.jpg\")\n",
    "a=cv2.cvtColor(image,cv2.COLOR_BGR2GRAY)\n",
    "cv2.imshow(\"hello\",a)\n",
    "cv2.waitKey()\n",
    "cv2.destroyWindow(\"hello\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# option 3:- by color spliting .\n",
    "image=cv2.imread(r\"C:\\Users\\Paramjeet\\Desktop\\MACHINE LEARNING\\Image\\demo.jpg\")\n",
    "b,g,r=cv2.split(image)\n",
    "cv2.imshow(\"blue\",b)\n",
    "cv2.imshow(\"Green\",g)\n",
    "cv2.imshow(\"Red\",r)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge the all color :-\n",
    "rt=cv2.merge([b,g,r])\n",
    "cv2.imshow(\"Red\",rt)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "image=cv2.imread(r\"C:\\Users\\Paramjeet\\Desktop\\MACHINE LEARNING\\Image\\me.jpg\")\n",
    "b,g,r=cv2.split(image)\n",
    "cv2.imshow(\"blue\",b)\n",
    "cv2.imshow(\"Green\",g)\n",
    "cv2.imshow(\"Red\",r)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Play with image.\n",
    "img7=cv2.imread(r\"C:\\Users\\Paramjeet\\Desktop\\MACHINE LEARNING\\Image\\demo.jpg\")\n",
    "img2=cv2.convertScaleAbs(img,alpha=2,beta=45)   #alpha works on edgeor sharpness\n",
    "cv2.imshow(\"Scale\",img2) \n",
    "cv2.imshow(\"Orignal\",img7)                        #beta work on brigtness.\n",
    "cv2.waitKey(10000 ) \n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# marge  2 photos\n",
    "image=cv2.imread(r\"C:\\Users\\Paramjeet\\Desktop\\MACHINE LEARNING\\Image\\me.jpg\")\n",
    "img3=cv2.resize(image,(735,742))\n",
    "cv2.imwrite(r\"C:\\Users\\Paramjeet\\Desktop\\MACHINE LEARNING\\Image\\me_resize.jpg\",img3)\n",
    "img=cv2.imread(r\"C:\\Users\\Paramjeet\\Desktop\\MACHINE LEARNING\\Image\\me_resize.jpg\")\n",
    "cv2.imshow(\"orginal\",image) \n",
    "cv2.imshow(\"Resize\",img)                        #beta work on brigtness.\n",
    "cv2.waitKey() \n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=cv2.addWeighted(img,0.5,img7,0.3,10) \n",
    "cv2.imshow(\"Merge\",a)                    \n",
    "cv2.waitKey() \n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# --> Face Detection in open cv by  mannual method :-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "x=230\n",
    "y=240\n",
    "w=250\n",
    "h=240\n",
    "face=cv2.imread(r\"C:\\Users\\Paramjeet\\Desktop\\MACHINE LEARNING\\Image\\demo.jpg\")\n",
    "cv2.rectangle(face,(x,y),(x+w,y+h),(255,0,0),2)\n",
    "cv2.imshow(\"window\",face)\\\n",
    "\n",
    "\n",
    "cv2.waitKey()\n",
    "cv2.destroyWindow(\"window\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# --> Face Detection in open cv by  Modal :-"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Github link :-\n",
    "\n",
    "# https://github.com/opencv/opencv/blob/master/data/haarcascades/haarcascade_frontalface_default.xml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.9.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\highgui\\src\\window_w32.cpp:1261: error: (-27:Null pointer) NULL window: 'face' in function 'cvDestroyWindow'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 10\u001b[0m\n\u001b[0;32m      8\u001b[0m cv2\u001b[38;5;241m.\u001b[39mimshow(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mface\u001b[39m\u001b[38;5;124m\"\u001b[39m,face)\n\u001b[0;32m      9\u001b[0m cv2\u001b[38;5;241m.\u001b[39mwaitKey()\n\u001b[1;32m---> 10\u001b[0m \u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdestroyWindow\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mface\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.9.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\highgui\\src\\window_w32.cpp:1261: error: (-27:Null pointer) NULL window: 'face' in function 'cvDestroyWindow'\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "modal=cv2.CascadeClassifier(cv2.data.haarcascades  +\"haarcascade_frontalface_default.xml\")\n",
    "face=cv2.imread(r\"C:\\Users\\Paramjeet\\Desktop\\MACHINE LEARNING\\Image\\group1.jpg\")\n",
    "g=cv2.cvtColor(face,cv2.COLOR_BGR2GRAY)\n",
    "faces=modal.detectMultiScale(g,scaleFactor=1.1,minNeighbors=2,minSize=(2,6))\n",
    "for x,y,w,h  in faces:\n",
    "    cv2.rectangle(face,(x,y),(x+w,y+h),(255,0,0),2)\n",
    "cv2.imshow(\"face\",face)\n",
    "cv2.waitKey()\n",
    "cv2.destroyWindow(\"face\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Video :- it is a No. of image which play in sequance in a second. which is mesure by fps (frame per second). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def camra():\n",
    "    import cv2\n",
    "    cap=cv2.VideoCapture(0)\n",
    "    fourcc=cv2.VideoWriter_fourcc(*\"XVID\")\n",
    "    out=cv2.VideoWriter(\"hello.mp4\",fourcc,20.0,(640,480))\n",
    "    while True:\n",
    "        ret,frame=cap.read()\n",
    "        cv2.imshow(\"Hello\",frame)\n",
    "        out.write(frame)\n",
    "        if cv2.waitKey(1) & 0xFF==ord(\"z\"):\n",
    "            break    \n",
    "    out.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "camra()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# face detection in video :-\n",
    "import cv2\n",
    "cap=cv2.VideoCapture(0)\n",
    "modal=cv2.CascadeClassifier(cv2.data.haarcascades  +\"haarcascade_frontalface_default.xml\")\n",
    "while True:\n",
    "    ret,frame=cap.read()\n",
    "    g=cv2.cvtColor(frame,cv2.COLOR_BGR2GRAY)\n",
    "    faces=modal.detectMultiScale(g,scaleFactor=1.1,minNeighbors=2,minSize=(2,6))\n",
    "    for x,y,w,h  in faces:\n",
    "        cv2.rectangle(frame,(x,y),(x+w,y+h),(255,0,0),2)\n",
    "        cv2.imshow(\"Hello\",frame)\n",
    "    if cv2.waitKey(1) & 0xFF==ord(\"z\"):\n",
    "        break\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[63], line 11\u001b[0m\n\u001b[0;32m      9\u001b[0m i_a\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39marray(\u001b[38;5;28mbytearray\u001b[39m(url1\u001b[38;5;241m.\u001b[39mcontent),dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39muint8)\n\u001b[0;32m     10\u001b[0m img2\u001b[38;5;241m=\u001b[39mcv2\u001b[38;5;241m.\u001b[39mimdecode(i_a,\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m---> 11\u001b[0m img\u001b[38;5;241m=\u001b[39m\u001b[43mimutils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m,\u001b[49m\u001b[43mwidth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1800\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mheight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1000\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     12\u001b[0m cv2\u001b[38;5;241m.\u001b[39mimshow(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHello\u001b[39m\u001b[38;5;124m\"\u001b[39m,img)\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cv2\u001b[38;5;241m.\u001b[39mwaitKey(\u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m27\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\Paramjeet\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\imutils\\convenience.py:69\u001b[0m, in \u001b[0;36mresize\u001b[1;34m(image, width, height, inter)\u001b[0m\n\u001b[0;32m     65\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mresize\u001b[39m(image, width\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, height\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, inter\u001b[38;5;241m=\u001b[39mcv2\u001b[38;5;241m.\u001b[39mINTER_AREA):\n\u001b[0;32m     66\u001b[0m     \u001b[38;5;66;03m# initialize the dimensions of the image to be resized and\u001b[39;00m\n\u001b[0;32m     67\u001b[0m     \u001b[38;5;66;03m# grab the image size\u001b[39;00m\n\u001b[0;32m     68\u001b[0m     dim \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m---> 69\u001b[0m     (h, w) \u001b[38;5;241m=\u001b[39m \u001b[43mimage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m[:\u001b[38;5;241m2\u001b[39m]\n\u001b[0;32m     71\u001b[0m     \u001b[38;5;66;03m# if both the width and height are None, then return the\u001b[39;00m\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;66;03m# original image\u001b[39;00m\n\u001b[0;32m     73\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m width \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m height \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import imutils\n",
    "import requests\n",
    "url=\"http://192.168.170.89:8080/\"\n",
    "\n",
    "while True:\n",
    "    url1=requests.get(url)\n",
    "    i_a=np.array(bytearray(url1.content),dtype=np.uint8)\n",
    "    img2=cv2.imdecode(i_a,-1)\n",
    "    img=imutils.resize(img,width=1800,height=1000)\n",
    "    cv2.imshow(\"Hello\",img)\n",
    "    if cv2.waitKey(1) == 27:\n",
    "        break\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting imutils\n",
      "  Downloading imutils-0.5.4.tar.gz (17 kB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Building wheels for collected packages: imutils\n",
      "  Building wheel for imutils (pyproject.toml): started\n",
      "  Building wheel for imutils (pyproject.toml): finished with status 'done'\n",
      "  Created wheel for imutils: filename=imutils-0.5.4-py3-none-any.whl size=25855 sha256=40e529080cda92890cfa925ffe0aed0065b8744ec9142c0ba06598fd9671c2b1\n",
      "  Stored in directory: c:\\users\\paramjeet\\appdata\\local\\pip\\cache\\wheels\\31\\d0\\2c\\87ce38f6052879e5b7b18f0f8b4a10ad2a9d210e908d449f16\n",
      "Successfully built imutils\n",
      "Installing collected packages: imutils\n",
      "Successfully installed imutils-0.5.4\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.3.2 -> 24.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install imutils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
